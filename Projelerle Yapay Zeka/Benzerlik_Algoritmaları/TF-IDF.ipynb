{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://miro.medium.com/v2/resize:fit:1100/format:webp/1*qQgnyPLDIkUmeZKN2_ZWbQ.png' width='750' height='450'> [Görsel kaynağı](https://towardsdatascience.com/tf-term-frequency-idf-inverse-document-frequency-from-scratch-in-python-6c2b61b78558)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Nedir\n",
    "\n",
    "**Term Frequency – Inverse Document Frequency**\n",
    "\n",
    "TF-IDF, bir kelimenin doküman içerisindeki anlam yoğunluğunu istatistiksel yöntemlerle tespit ederek belirli bir ağırlık değeri bulmayı amaçlar. Ortaya çıkan bu TF-IDF değeri, terimin dokümanda ne kadar sık geçtiği ve doküman kümesinde ne kadar nadir olduğu ile orantılıdır. Böylece, dokümanların içeriğini yansıtan ve ayırt edici kelimeleri tespit etmek mümkün olur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF (Term Frequency)\n",
    "**TF = (Belirli bir kelimenin belgedeki tekrar sayısı) / (Dokümandaki toplam kelime sayısı)**\n",
    "\n",
    "Örnek olarak, bir dokümanda *<b>filhakika</b>* kelimesisnin 10 kere geçtiğini varsayalım ve dokümanın tamamı da 500 kelime olsun. Bu durumda, filhakika kelimesinin terim frekansı $10/500 = 0.02$ olarak bulunmuş olur.\n",
    "\n",
    "Bir terimin sık kullanılması, genellikle o terimin önemli bir bilgi içerdiğini gösterirken, tüm doküman kümesinde nadir bulunması, terimin diğerlerinden farklı ve özgün olduğu anlamına gelebilir. \n",
    "\n",
    "Ayrıca burada şöyle bir handikap vardır, **Stop Words**. Bunun ne ifade ettiğini anlamak için Türkçe dilindeki stop words sayılan kelimelere baktığımızda  *ama, bu, şu, ve, gibi* vs. sözcükler görürüz. Bu sözcükler doküman içerisinde çokça geçebilir olmasına rağmen bun kelimelerin temsil ettiği büyük bir anlam yoktur ve sıklıklarından dolayı TF işleminde gereksiz bir ağırlık kazanabilirler. Dolayısıyla stop words olarak adlandırılan bu kelimlerin işlemin daha anlamlı olabilmesi için, kelime vektörleri oluşturulmadan önce dokumandan ayıklanmalıdırlar. (İngilizce Stop Words örnekleri: *is, on, the, in, of, it* etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IDF (Inverse Document Frequency)\n",
    "\n",
    "**IDF = log((Toplam doküman sayısı) / (Belirli kelime içeren doküman sayısı))**\n",
    "\n",
    "$IDF(t) = log(N / (1 + DF(t)))$\n",
    "\n",
    "$IDF = \\log\\left(\\frac{\\text{Toplam Dokuman Sayisi}}{\\text{Kelimenin Essiz Dokuman Sayisi}}\\right)$\n",
    "\n",
    "\n",
    "Burada:\n",
    "   - N: Toplam doküman sayısı.\n",
    "   - DF(t): Belirli bir kelimenin geçtiği doküman sayısı.\n",
    "   \n",
    "IDF, bir kelimenin doküman kümesi içerisindeki nadirliğini gösterir. Bu sayede kelimenin doküman içerisindeki önemini belirlemeye yardımcı olur. IDF değeri, tüm dokümanlar üzerinden hesaplanır.\n",
    "\n",
    "IDF, logaritmik bir ölçeğe sahip olduğundan dolayı nadir kelimelerin büyük değerler almasını engeller ve daha dengeli bir ölçüm değeri sunar. Eğer bir kelime doküman kümesi içerisinde sıkça geçiyorsa, IDF değeri düşük olacaktır ve bu kelime, muhtemelen genel bilgi taşıyan ve metinler arasında ayrımcılık yapmayan yaygın bir kelimeye tekabul edecektir. Tüm dokümanlar içerisinde az geçen bir kelimenin IDF değeri ise büyük olacaktır."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF\n",
    "TF-IDF, her terimin doküman içerisindeki sıklığını (TF) ve tüm doküman koleksiyonu içerisinde o terimin ne kadar yaygın olduğunu (IDF) birleştirerek (çarparak) hesaplanır. \n",
    "\n",
    "<b>$TF-IDF(d, t) = TF(d, t) * IDF(t)$</b>\n",
    "\n",
    "Burada:\n",
    "- $TF(d, t)$ : Belirli bir dokümandaki (d) terimin (t) geçme sıklığı. Yani, dokümandaki terimin tekrar sayısı.\n",
    "- $IDF(t$) : Tüm dokümanlardaki (corpus) terimin (t) geçme sıklığının tersi. \n",
    "\n",
    "Sonuç olarak en yüksek ağırlık değeri, bir kelimenin az sayıda dokümanda birçok kez geçtiği zaman ortaya çıkar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python ile Uygulama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['acaba', 'ama', 'ancak', 'artık', 'asla', 'aslında', 'az', 'bana', 'bazen', 'bazı', 'belki',\n",
    "            'ben','beni', 'bu','benim', 'beri', 'bile', 'bir', 'biri', 'birkaç', 'birçok', 'şey', 'daha',\n",
    "            'az', 'gene','gibi', 'da', 'de', 'en', 'daha','diğer', 'diğeri' , 'diye', 'dolayı', 'fakat',\n",
    "            'falan', 'filan', 'gibi', 'hala', 'hatta', 'ise', 'kim', 'kime', 'niye', 'oysa', 'pek',\n",
    "            'rağmen', 'sanki', 'şayet', 'sen', 'siz', 'tabii', 've', 'veya', 'zira']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF işlemi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "örnek: 0.3\n",
      "dokümandır: 0.1\n",
      "dokümanda: 0.1\n",
      "tf: 0.1\n",
      "işlemi: 0.1\n",
      "yapacağız: 0.1\n",
      "deneme: 0.2\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def kelime_listesi(dokuman):\n",
    "    liste = []\n",
    "    for kelime in dokuman: \n",
    "        kelimeler = kelime.split(' ')  \n",
    "        for kelime in kelimeler:  \n",
    "            kelime = re.sub(r'[^\\w\\s]', '', kelime)  \n",
    "            if kelime.lower() not in stop_words:\n",
    "                liste.append(kelime.lower())\n",
    "    return liste\n",
    "\n",
    "def dokuman_boyutu(liste):\n",
    "    return len(liste)\n",
    "\n",
    "def frekans(liste):\n",
    "    frekans = {}\n",
    "    for kelime in liste:\n",
    "        if kelime in frekans:\n",
    "            frekans[kelime] += 1\n",
    "        else:\n",
    "            frekans[kelime] = 1\n",
    "    return frekans\n",
    "\n",
    "def tf_degeri(frekans, boyut):\n",
    "    for anahtar, deger in frekans.items():\n",
    "        tf = deger/boyut\n",
    "        print(f'{anahtar}: {tf}')\n",
    "    \n",
    "def main(dokuman):\n",
    "    degerler = kelime_listesi(dokuman)\n",
    "    boyut = dokuman_boyutu(degerler)\n",
    "    frekans_degerleri = frekans(degerler)\n",
    "    tf = tf_degeri(frekans_degerleri, boyut)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    dokuman = ['Bu bir örnek dokümandır. Bu örnek dokümanda TF işlemi yapacağız.', 'deneme, deneme örnek']\n",
    "    main(dokuman)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF işlemi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " TF degerleri: \n",
      "\n",
      "örnek: 0.2222222222222222\n",
      "dokümandır: 0.1111111111111111\n",
      "dokümanda: 0.1111111111111111\n",
      "tf: 0.1111111111111111\n",
      "işlemi: 0.1111111111111111\n",
      "yapacağız: 0.1111111111111111\n",
      "deneme: 0.2222222222222222\n",
      "\n",
      "---------------------------\n",
      "\n",
      " IDF degerleri: \n",
      "\n",
      "örnek: 0.0\n",
      "dokümandır: 0.6931471805599453\n",
      "dokümanda: 0.6931471805599453\n",
      "tf: 0.6931471805599453\n",
      "işlemi: 0.6931471805599453\n",
      "yapacağız: 0.6931471805599453\n",
      "deneme: 0.0\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import math \n",
    "\n",
    "def kelime_listesi(dokuman):\n",
    "    liste = []\n",
    "    for kelime in dokuman: \n",
    "        kelimeler = kelime.split(' ')  \n",
    "        for kelime in kelimeler:  \n",
    "            kelime = re.sub(r'[^\\w\\s]', '', kelime)  \n",
    "            if kelime.lower() not in stop_words:\n",
    "                liste.append(kelime.lower())\n",
    "    return liste\n",
    "\n",
    "def dokuman_boyutu(liste):\n",
    "    return len(liste)\n",
    "\n",
    "def frekans(liste):\n",
    "    frekans = {}\n",
    "    for kelime in liste:\n",
    "        if kelime in frekans:\n",
    "            frekans[kelime] += 1\n",
    "        else:\n",
    "            frekans[kelime] = 1\n",
    "    return frekans\n",
    "\n",
    "def tf_degeri(frekans, boyut):\n",
    "    for anahtar, deger in frekans.items():\n",
    "        tf = deger/boyut\n",
    "        print(f'{anahtar}: {tf}')\n",
    "\n",
    "\n",
    "def idf_degeri(frekans_degerleri):  \n",
    "    idf_boyut = dokuman_boyutu(dokuman)\n",
    "    for anahtar, deger in frekans_degerleri.items():\n",
    "        idf = math.log(idf_boyut / deger)\n",
    "        print(f'{anahtar}: {idf}')\n",
    "    \n",
    "    \n",
    "    \n",
    "def main(dokuman):\n",
    "    \n",
    "    degerler = kelime_listesi(dokuman)\n",
    "    boyut = dokuman_boyutu(degerler)\n",
    "    \n",
    "    frekans_degerleri = frekans(degerler)\n",
    "    \n",
    "    print('\\n TF degerleri: \\n')\n",
    "    tf = tf_degeri(frekans_degerleri, boyut)\n",
    "    print('\\n---------------------------')\n",
    "    print('\\n IDF degerleri: \\n')\n",
    "    idf = idf_degeri(frekans_degerleri)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    dokuman = ['Bu bir örnek dokümandır. Bu örnek dokümanda TF işlemi yapacağız.', 'deneme, deneme']\n",
    "    main(dokuman)       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
